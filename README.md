# AISorter Backend

Ce dÃ©pÃ´t contient le backend de l'application **AISorter**, une solution de dÃ©tection et de classification d'incidents de sÃ©curitÃ© basÃ©e sur le Machine Learning. Il expose une API REST dÃ©veloppÃ©e avec **FastAPI** qui permet d'analyser des fichiers de logs (CSV/Excel), de prÃ©dire la nature des incidents et de gÃ©nÃ©rer des rapports dÃ©taillÃ©s.

Le frontend de l'application est disponible ici : [AISorter Frontend](https://github.com/Tmaxpro/AISorter-Frontend)

## ğŸš€ FonctionnalitÃ©s

- **API REST performante** : Construite avec FastAPI pour une rÃ©ponse rapide et une documentation automatique.
- **Analyse de fichiers** : Supporte l'upload de fichiers `.csv` et `.xlsx` pour l'analyse.
- **Pipeline Machine Learning** :
  - **PrÃ©traitement** : Nettoyage et transformation des donnÃ©es brutes.
  - **PrÃ©diction** : Classification des incidents Ã  l'aide d'un modÃ¨le Scikit-learn entraÃ®nÃ©.
  - **Post-traitement** : GÃ©nÃ©ration de rapports d'incidents enrichis.
- **Enrichissement des donnÃ©es** : IntÃ©gration avec des services tiers (ex: AbuseIPDB) pour la rÃ©putation des IP.
- **Historique** : Stockage des rapports d'analyse dans une base de donnÃ©es **MongoDB**.

## ğŸ“‚ Structure du Projet

```
backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py          # Point d'entrÃ©e de l'API (Routes /predict, /history)
â”‚   â”œâ”€â”€ database.py      # Connexion Ã  MongoDB
â”‚   â””â”€â”€ ...
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ config.py        # Gestion des variables d'environnement
â”‚   â””â”€â”€ ...
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ model/           # Logique de chargement du modÃ¨le et prÃ©diction
â”‚   â”œâ”€â”€ preprocessing/   # Pipelines de nettoyage des donnÃ©es
â”‚   â”œâ”€â”€ postprocessing/  # GÃ©nÃ©ration de rapports et scoring
â”‚   â””â”€â”€ ...
â”œâ”€â”€ requirements.txt     # DÃ©pendances Python
â””â”€â”€ README.md            # Documentation du projet
```

## ğŸ› ï¸ PrÃ©requis

- **Python 3.10+**
- **MongoDB** (Local ou Atlas)
- ClÃ©s API pour les services externes (si applicable, ex: AbuseIPDB, OpenAI/LLM pour les rapports).

## ğŸ“¦ Installation

1. **Cloner le dÃ©pÃ´t**

   ```bash
   git clone https://github.com/Tmaxpro/AISorter-Backend.git
   cd AISorter-Backend
   ```

2. **CrÃ©er un environnement virtuel**

   ```bash
   python -m venv venv
   source venv/bin/activate  # Sur Windows: venv\Scripts\activate
   ```

3. **Installer les dÃ©pendances**

   ```bash
   pip install -r requirements.txt
   ```

4. **Configuration**

   CrÃ©ez un fichier `.env` Ã  la racine du projet en vous basant sur les variables nÃ©cessaires (voir `core/config.py`) :

   ```env
   MONGO_URL=mongodb://localhost:27017
   DB_NAME=aisorter_db
   COLLECTION_NAME=reports
   MODEL_PATH=ml/model/trained_model.pkl
   TRAINING_DATA_PATH=ml/model/training/training_data/
   API_KEY=votre_api_key_llm
   ABUSEIPDB_KEY=votre_cle_abuseipdb
   ```

## â–¶ï¸ DÃ©marrage

Pour lancer le serveur de dÃ©veloppement :

```bash
uvicorn app.main:app --reload
```

L'API sera accessible Ã  l'adresse : `http://127.0.0.1:8000`

## ğŸ“š Documentation de l'API

Une fois le serveur lancÃ©, la documentation interactive est disponible automatiquement :

- **Swagger UI** : [http://127.0.0.1:8000/docs](http://127.0.0.1:8000/docs)
- **ReDoc** : [http://127.0.0.1:8000/redoc](http://127.0.0.1:8000/redoc)

### Endpoints Principaux

- `POST /predict` : Upload d'un fichier pour analyse et gÃ©nÃ©ration de rapport.
- `GET /history` : RÃ©cupÃ¨re la liste des analyses prÃ©cÃ©dentes.
- `GET /history/{report_id}` : RÃ©cupÃ¨re les dÃ©tails d'un rapport spÃ©cifique.

## ğŸ§  Machine Learning

Le dossier `ml/` contient toute la logique mÃ©tier liÃ©e Ã  l'IA :

1. **Preprocessing** : Les donnÃ©es entrantes sont nettoyÃ©es (`cleaning.py`) et transformÃ©es pour correspondre au format attendu par le modÃ¨le.
2. **ModÃ¨le** : Le modÃ¨le (`predictor.py`) effectue la classification des incidents.
3. **Postprocessing** : Les rÃ©sultats bruts sont transformÃ©s en un rapport JSON structurÃ©, enrichi avec des scores de rÃ©putation et des explications (`processor.py`, `reputation.py`).

### EntraÃ®nement du ModÃ¨le

Le script d'entraÃ®nement se trouve dans `ml/model/training/training.py`. Il utilise un algorithme **Random Forest Classifier** optimisÃ© pour la classification d'incidents.

**Processus d'entraÃ®nement :**

1. **Chargement des donnÃ©es** : Les donnÃ©es d'entraÃ®nement sont chargÃ©es depuis le chemin spÃ©cifiÃ© dans `TRAINING_DATA_PATH`.
2. **PrÃ©traitement** :
   - Nettoyage initial via `DataPreprocessor`.
   - GÃ©nÃ©ration de features (ex: hachage).
   - Transformation des colonnes (OneHotEncoding, LabelEncoding, StandardScaling) via un `ColumnTransformer`.
3. **Pipeline** : Un pipeline Scikit-learn intÃ¨gre toutes les Ã©tapes de transformation et le classifieur final.
4. **Ã‰valuation** :
   - Split Train/Test (80/20).
   - Validation croisÃ©e (Stratified K-Fold, 5 splits) pour assurer la robustesse.
   - MÃ©triques suivies : Accuracy, Precision, Recall, F1-score, ROC-AUC.
5. **Sauvegarde** : Le modÃ¨le final, entraÃ®nÃ© sur l'ensemble des donnÃ©es, est sauvegardÃ© au format `.pkl` (Joblib).

Pour lancer un rÃ©entraÃ®nement manuel :

```bash
python -m ml.model.training.training
```

## ğŸ¤ Contribution

Les contributions sont les bienvenues ! N'hÃ©sitez pas Ã  ouvrir une issue ou une Pull Request.